{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_selection\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     12\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.5-py3-none-win_amd64.whl (70.9 MB)\n",
      "     ---------------------------------------- 70.9/70.9 MB 8.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\sesa662668\\appdata\\local\\anaconda3\\lib\\site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sesa662668\\appdata\\local\\anaconda3\\lib\\site-packages (from xgboost) (1.23.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.5\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data for training \n",
    "train = pd.read_csv('train_sample.csv', sep=',')\n",
    "# Select only 5000 obs. to show demo\n",
    "train = train.head(5000)\n",
    "train = train.drop('ID_code', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction data\n",
    "preddata = pd.read_csv('test_sample.csv', sep=',')\n",
    "predids = preddata[['ID_code']] \n",
    "preddata = preddata.drop('ID_code', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format train data\n",
    "y_train = train['target']\n",
    "x_train = train.drop('target', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaled_df = scaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(scaled_df)\n",
    "scaled_df = scaler.fit_transform(preddata)\n",
    "preddata = pd.DataFrame(scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y to np \n",
    "x_train = x_train.values\n",
    "y_train = y_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to train and stack some models. Here I use Logistic Regression, RF. The tree models will be stacked using xgboost. In the code below, the models and the stacking classifier are defined first. Then each model is trained using CV.\n",
    "\n",
    "Finally,the stacking classifier is fitted and predictions are obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st set of models\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = RandomForestClassifier(random_state=1, n_estimators=10) # just for demo have taken 10 trees \n",
    "xgb = XGBClassifier()\n",
    "\n",
    "stacking_demo = StackingCVClassifier(classifiers=[clf1, clf2], meta_classifier=xgb, use_probas=True, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.61 (+/- 0.04) [lr]\n",
      "Accuracy: 0.58 (+/- 0.03) [Random Forest]\n",
      "Accuracy: nan (+/- nan) [StackingClassifier]\n"
     ]
    }
   ],
   "source": [
    "# Do CV\n",
    "for clf, label in zip([clf1, clf2, stacking_demo], \n",
    "                      ['lr', \n",
    "                       'Random Forest', \n",
    "                       'StackingClassifier']):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, x_train, y_train, cv=3, scoring='roc_auc')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ID_code    target\n",
      "0  test_0  0.024918\n",
      "1  test_1  0.069463\n",
      "2  test_2  0.239636\n",
      "3  test_3  0.036264\n",
      "4  test_4  0.018864\n"
     ]
    }
   ],
   "source": [
    "# Fit on train data / predict on test data\n",
    "sclf_fit = stacking_demo.fit(x_train, y_train)\n",
    "mypreds = sclf_fit.predict_proba(preddata)\n",
    "# \"predict\" give us classes, \"predict_proba\" give us probabilities\n",
    "\n",
    "# Probabilities for classes (1,0)\n",
    "zeros = [i[0] for i in mypreds]\n",
    "ones  = [i[1] for i in mypreds]\n",
    "\n",
    "# Get IDs and predictions\n",
    "y_id = predids.values.tolist()\n",
    "preddf = pd.DataFrame({'ID_code': y_id,'target': ones})\n",
    "preddf['ID_code'] = preddf['ID_code'].map(lambda x: str(x)[:-2])\n",
    "preddf['ID_code'] = preddf['ID_code'].map(lambda x: str(x)[2:])\n",
    "\n",
    "# Look at predictions\n",
    "print(preddf.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
